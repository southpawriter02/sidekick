# Sidekick v0.8.1 Changelog â€” LM Studio Connection

> **Release Date:** 2026-02-05  
> **Phase:** LLM Integration (v0.8.x)

---

## Summary

This release adds **LM Studio Connection** â€” discovery, connection, and model management for local LLMs.

---

## New Features

### ðŸ”Œ LM Studio Integration

- **Server Connection:** Connect to LM Studio servers via OpenAI-compatible API
- **Auto-Discovery:** Find LM Studio servers on common ports
- **Model Management:** List, select, and track loaded models
- **Streaming Chat:** Real-time streaming responses via SSE
- **Function Calling:** Tool/function definitions for agent support
- **Embeddings:** Generate embeddings for semantic search

### Connection Features

| Feature | Description |
|---------|-------------|
| Auto-Connect | Connect to LM Studio on startup |
| Auto-Discover | Scan for servers on common ports |
| Health Check | Monitor connection status |
| Timeout Config | Configurable connection/request timeouts |

### Model Capabilities

| Capability | Description |
|------------|-------------|
| Chat | Conversational completions |
| Completion | Text completion |
| Code | Code generation |
| Embedding | Vector embeddings |
| Function Calling | Tool use for agents |
| Vision | Image understanding |

### Supported Model Families

- LLaMA, Code Llama
- Mistral, Mixtral
- DeepSeek
- Qwen
- Phi
- Gemma
- StarCoder

---

## Components Added

### Models (`LmStudioModels.kt`)

| Type | Description |
|------|-------------|
| `LmStudioConfig` | Server connection settings |
| `LmStudioModel` | Available model info |
| `ModelFamily` | 9 model families |
| `ModelCapability` | 6 capability flags |
| `ConnectionStatus` | Connection state |
| `ChatCompletionRequest` | Chat request (OpenAI format) |
| `ChatMessage` | Conversation message |
| `ChatCompletionResponse` | Chat response |
| `ToolDefinition` | Function calling tool |
| `StreamingChunk` | SSE streaming chunk |
| `DiscoveryResult` | Server discovery result |

### Service (`LmStudioService.kt`)

| Feature | Description |
|---------|-------------|
| Connection | Connect, check, disconnect |
| Models | List, select, refresh |
| Chat | Streaming and non-streaming |
| Embeddings | Text to vector |
| Discovery | Find servers on network |

### Settings (`LmStudioSettingsPanel.kt`)

| Component | Description |
|-----------|-------------|
| Connection UI | Host, port, timeouts |
| Model Selection | Dropdown with refresh |
| Test Connection | Verify server access |
| Discover | Find servers |

---

## Files Changed

### New Files
- `src/main/kotlin/com/sidekick/llm/lmstudio/LmStudioModels.kt`
- `src/main/kotlin/com/sidekick/llm/lmstudio/LmStudioService.kt`
- `src/main/kotlin/com/sidekick/llm/lmstudio/LmStudioSettingsPanel.kt`
- `src/test/kotlin/com/sidekick/llm/lmstudio/LmStudioModelsTest.kt`
- `src/test/kotlin/com/sidekick/llm/lmstudio/LmStudioServiceTest.kt`

---

## Test Coverage

| Test Class | Tests | Coverage |
|------------|-------|----------|
| `LmStudioModelsTest` | 50+ | All models and enums |
| `LmStudioServiceTest` | 30+ | State, parsing, building |

---

## API Reference

### Connecting
```kotlin
val service = LmStudioService.getInstance()
service.checkConnection() // Returns ConnectionStatus
```

### Chat
```kotlin
val request = ChatCompletionRequest.simple("llama-3.1", "Hello!")
val response = service.chat(request)
```

### Streaming
```kotlin
service.streamChat(request).collect { token ->
    print(token)
}
```

---

## Verification

```bash
./gradlew test --tests "com.sidekick.llm.lmstudio.*"
# All tests passing
```
